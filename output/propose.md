The proposition that there needs to be strict laws to regulate Large Language Models (LLMs) is a paramount necessity in today's technologically advancing world. LLMs have the capability to process and generate vast amounts of data, which, if not properly regulated, can lead to severe consequences. 

Firstly, the potential for LLMs to spread misinformation and disinformation is incredibly high. Without strict regulations, these models can be exploited by malicious actors to disseminate false information on a massive scale, leading to societal chaos, erosion of trust in institutions, and even physical harm. For instance, in the context of public health, the spread of false information about vaccines or treatments can lead to decreased vaccination rates and increased mortality. Strict laws regulating the use and development of LLMs can mitigate this risk by enforcing fact-checking mechanisms, accountability for the spread of misinformation, and transparency in the data these models are trained on.

Secondly, LLMs pose significant privacy and data protection concerns. These models are often trained on vast datasets that include personal information, which, if not anonymized or protected properly, can lead to privacy violations. Strict laws can ensure that developers of LLMs adhere to robust data protection standards, including obtaining informed consent for data use, anonymizing personal data where possible, and implementing robust security measures to prevent data breaches.

Thirdly, the lack of transparency and explainability in LLMs' decision-making processes can lead to discriminatory outcomes. These models can inadvertently (or intentionally, if manipulated) perpetuate biases present in their training data, resulting in unfair treatment of certain groups of people. For example, in recruitment processes, LLMs might discriminate against candidates based on gender, race, or age if their training data reflects societal biases. Strict regulations can mandate the development of more transparent and explainable AI models, requiring developers to test for and mitigate such biases.

Furthermore, strict laws can also foster innovation by providing a clear and stable regulatory environment. Knowing what is and isn't permissible can encourage more entities to invest in LLM development, assured that their investments will not be undermined by legal ambiguities or future crackdowns. This can lead to more responsible innovation, where the focus is not just on the capability of the technology but also on its ethical implications and societal benefits.

In conclusion, the necessity for strict laws to regulate LLMs is not just a precautionary measure but a crucial step towards ensuring that these powerful technologies are developed and used in ways that benefit society as a whole. By addressing the challenges of misinformation, privacy, discrimination, and fostering responsible innovation, strict regulations can help maximize the benefits of LLMs while minimizing their risks. Therefore, it is imperative that governments and regulatory bodies around the world take proactive steps to establish and enforce strict laws governing the development and deployment of LLMs.